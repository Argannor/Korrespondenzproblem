\documentclass[]{scrartcl}


\usepackage[ngerman]{babel}
\usepackage{default}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}

\usepackage[
	hyperref=true,          % Klickbare Referenzen in der PDF-Datei
  	backref=true,           % In der Literaturref. die Seiten angeben, wo ein \cite dazu steht
  	bibencoding=inputenc,   % s. inputenc-Paket
  	backend = biber,
  	style = alphabetic,			% [Aut98]
	%style=authoryear-comp,	% Autor Jahr
	%style=numeric-comp,		% [1]
	sorting=nty]{biblatex}  % http://dante.ctan.org/tex-archive/help/Catalogue/entries/biblatex.html
\bibliography{ausarbeitung}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

\newtheorem{definition}{Definition}[section]
\newtheorem{satz}[definition]{Satz}
\newtheorem{bsp}[definition]{Beispiel}

%opening
\title{Postsches Korrespondenzproblem}
\author{Soeren Berken-Mersmann}
\titlehead{\Large DHBW-Karlsruhe}
\publishers{Betreut durch Prof. Dr. Heinrich Braun}


\begin{document}

\maketitle

\section{Einleitung}

	Diese Ausarbeitung soll mit Hilfe des Postschen Korrespondenzproblems zeigen, dass es einfacher sein kann einem Problem eine Eigenschaft nachzuweisen in dem ein Zwischenschritt über ein anderes Problem gemacht wird. Konkret soll dieses Verfahren für die Nichtberechenbarkeit zweier Probleme der kontextfreien Grammatiken bewiesen werden: Der Mehrdeutigkeitstest und das Äquivalenzproblem.
	
	Hierbei wird zuerst das Postsche Korrespondenzproblem (PKP) vorgestellt und erläutert. Anschließend wird das Halteproblem für Turingmaschinen darauf reduziert um im Abschluss das PKP auf die oben genannten Probleme zu reduzieren um deren Nichtberechenbarkeit zu beweisen.

\section{Postsches Korrespondenzproblem}

	\subsection{Definition}
	
		Das Postsches Korrespondenzproblem (PKP) ist benannt nach Emil Leon Post. Es handelt sich um ein konstruiertes Problem aus der theoretischen Informatik und ist folgendermaßen definiert (vgl. \cite{wegener}):
		
		\begin{definition}
			Gegeben sei eine endliche Menge an Wortpaaren $K = \left\lbrace (x_1, y_1), ..., (x_k, y_k)\right\rbrace $, über dem Alphabet $\Sigma$ mit $x_i, y_i \in \Sigma$. Gibt es eine Folge von Indizes $i_1, i_2, ..., i_n \in \{1, 2, ..., k\}, n \geq 1$, so dass $x_{i_1},x_{i_2}, ... x_{i_n} = y_{i_1}, y_{i_2}, ..., y_{i_n}$ gilt?
		\end{definition}
		
		Das Problem lässt sich besser Visualisieren als Menge von Dominosteinen: Ein Dominostein besteht jeweils aus einem oberen ($x_i$) und unteren ($y_i$) Symbol aus dem Alphabet $\Sigma$. Die Fragestellung lautet nun, ob es eine Reihenfolge gibt in der die Dominosteine so aneinandergereiht werden können, dass oben und unten die selbe Symbolfolge entsteht. Dabei darf jeder Dominostein mehrfach verwendet werden. Diese Arbeit wird daher eine Schreibweise verwenden, die diese Visualisierung widerspiegelt.
	
	\subsection{Beispiele des PKPs}
		
		Dieser Abschnitt wird an Hand von drei Beispielen zeigen, dass die Lösung des PKPs nicht trivial ist.

		\begin{bsp}
			\label{bsp-pkp1}
			Die Menge an Wortpaaren $K$ sei gegeben mit: \[K = \left\lbrace \begin{bmatrix}
					1 \\ 111
				\end{bmatrix}
				\begin{bmatrix}
					10111 \\ 10
				\end{bmatrix}
				\begin{bmatrix}
					10 \\ 0
				\end{bmatrix}\right\rbrace \]
				Die Lösung des PKPs lässt sich mit der Indexfolge $I_1 = (2, 1, 1, 3)$ angeben, so ergibt sich die Lösung:
				\[K_{I_1} = \begin{bmatrix}
								10111 \\ 10
							\end{bmatrix} \begin{bmatrix}
								1 \\ 111
							\end{bmatrix} \begin{bmatrix}
								1 \\ 111
							\end{bmatrix} \begin{bmatrix}
								10 \\ 0
							\end{bmatrix}\]
		\end{bsp}
		
		Das Beispiel \ref{bsp-pkp1} zeigt, dass es Instanzen des PKPs gibt für die sich eine Lösung finden lässt. Darüber hinaus handelt es sich um ein einfaches Beispiel, bei dem man mit ein wenig Knobelei selbst auf die Lösung kommen kann. Mit Hilfe der zwei nächsten Beispielen wird gezeigt, dass es sowohl weitaus komplexere Probleminstanzen gibt, die sich nicht mehr mit einem scharfen Blick lösen lassen (s. Beispiel \ref{bsp-pkp2}), als auch Fälle in denen es keine Lösung für das PKP gibt (Beispiel \ref{bsp-pkp3}).
		
		\begin{bsp}
			\label{bsp-pkp2}
			Die Instanz des PKPs sei gegeben mit der Menge an Wortpaaren $K$:
			\[K = \left\lbrace \begin{bmatrix}
						001 \\ 0
					\end{bmatrix}
					\begin{bmatrix}
						01 \\ 011
					\end{bmatrix}
					\begin{bmatrix}
						01 \\ 101
					\end{bmatrix}
					\begin{bmatrix}
						10 \\ 001
					\end{bmatrix}\right\rbrace \]
			Und ihre kürzeste Lösung ist $I_1$ mit insgesamt 66 Elementen:
			\begin{align*}
				I_1 = (2, 4, 3, 4, 4, 2, 1, 2, 4, 3, 4, 3, 4, 4, 3, 4, 4, 2, 1, 4, 4, 2, 1, 3, 4, 1, 1, 3, 4, 4, 4, 2, 1,\\ 2, 1, 1, 1, 3, 4, 3, 4, 1, 2, 1, 4, 4, 2, 1, 4, 1, 1, 3, 4, 1, 1, 3,
					1, 1, 3, 1, 2, 1, 4, 1, 1, 3 )
			\end{align*}
		\end{bsp}
		\begin{bsp}
			\label{bsp-pkp3}
			Die Instanz des PKPs sei gegeben mit der Menge an Wortpaaren $K$:
			\[K = \left\lbrace \begin{bmatrix}
						10 \\ 101
					\end{bmatrix}
					\begin{bmatrix}
						011 \\ 11
					\end{bmatrix}
					\begin{bmatrix}
						101 \\ 011
					\end{bmatrix}\right\rbrace \]
			Das einzige Wortpaar mit dem angefangen werden kann ist das erste. Darauf muss zwangsläufig das dritte Paar folgen.  Da nun die untere Wortfolge der oberen um ein Symbol vorauseilt, passt erneut nur das dritte Paar. Folglich kann die $y$-Folge nie aufschließen, und diese Instanz des PKPs hat keine Lösung.
			\[
			\begin{bmatrix}
						10 \\ 101
					\end{bmatrix} 
					\begin{bmatrix}
						101 \\ 011
					\end{bmatrix}
					\begin{bmatrix}
						101 \\ 011
					\end{bmatrix} ...
			\]
		\end{bsp}

\section{Beweis der Nichtberechenbarkeit}
	In diesem Kapitel soll die Nichtentscheidbarkeit des PKPs bewiesen werden, indem das Halteproblem für Turingmaschinen auf das PKP reduziert wird.

	\subsection{Simulation einer Turingmaschine}
		Dazu soll zuerst gezeigt werden, wie mit Hilfe des PKPs eine Turingmaschine simuliert werden kann. Dabei wird eine Turingmaschine mit einem beidseitig unendlichem Band und dem Bandalphabet $\varGamma = \{0,1\}$ verwendet, ohne Beschränkung der Allgemeinheit. Um die Turingmaschine mit Hilfe des PKPs simulieren zu können, muss zuerst ihr Rechenweg formalisiert werden. 
		
		
		\paragraph{Der Rechenweg einer Turingmaschine}
			Der Rechenweg beschreibt dabei die von der Turingmaschine durchlaufenen Zustände\footnote{Mit Zuständen wird der gesamte Zustand der Turingmaschine gemeint, und nicht der Zustand des Turingprogramms. Der Verständlichkeit halber wird dieser Programmzustand im Weiteren als interner Zustand bezeichnet.} vom Beginn der Berechnung bis zu einem (möglichen) Endzustand. Der Rechenweg ist folglich eine Folge von Zuständen.
			
			Der Zustand einer Turingmaschine lässt sich mit den folgenden Punkten vollständig beschreiben (Vgl. Abbildung \ref{img-turingsnapshot}):
			\begin{figure}
				\centering
				\includegraphics[width=0.85\linewidth]{../abbildungen/turing-snapshot}
				\caption{Illustration des Zustands einer Turingmaschine mit beidseitig unendlichem Band.}
				\label{img-turingsnapshot}
			\end{figure}
			
			\begin{itemize}
				\item Linkskontext: $u$
				\item Interner Zustand: $q$
				\item Gelesenes Symbol: $a$
				\item Rechtskontext: $w$
				\item Position des Lese- und Schreibkopfes
			\end{itemize}
			
			Das führt zu Satz \ref{satz-Turing-Zustand}:
			
			\begin{satz}
			\label{satz-Turing-Zustand}
			Der Zustand $Q_t$ einer Turingmaschine zum Zeitpunkt $t$ kann durch die Folge $Q_t = u_tq_ta_tw_t$ dargestellt werden. Dabei ist die Position des Lese- und Schreibkopfes durch die Position des internen Zustands innerhalb der Folge $Q_t$ kodiert. Folglich lassen sich das gelesene Symbol $a_t$ und der Rechtskontext $w_t$ auch zusammenfassen.
			\end{satz}
			
			Und mit Hilfe dieses Satzes kann der Rechenweg der Turingmaschine beschrieben werden:
			
			\begin{satz}
			Den Rechenweg einer Turingmaschine kann als Folge von Zuständen $Q_0, ..., Q_n$ vom Startzeitpunkt $t = 0$ bis zum Endzeitpunkt $t = n$ bei dem die Turingmaschine einen der Endzustände erreicht hat dargestellt werden.
			\end{satz}
		
		\paragraph{Simulation mit Hilfe des PKPs}
			Wir benötigen nun Regeln, um aus dem formalisierten Rechenweg einer Turingmaschine eine Instanz des speziellen PKPs\footnote{Das spezielle PKP hat die Einschränkung, dass eine Lösung mit dem ersten Wortpaar anfangen muss: $I = i_1, i_2, ..., i_n$ mit $i_1 = 1$.} konstruieren zu können. Das Ziel ist es, dass die Instanz des PKPs genau dann eine Lösung hat, wenn die damit simulierte Turingmaschine terminiert. Folglich spiegelt die Wortfolge des PKPs den Rechenweg der Turingmaschine wider.
			
			Die drei Kernkomponenten sind die Kopierregeln, mit denen die unveränderten Teile des Zustands (sprich der Links und der Rechtskontext) jeweils in den Folgezustand kopiert werden. Die Überführungsregeln, die die Zustandsübergangsfunktionen der Turingmaschine abbilden. Sowie die Aufholregeln die es dem PKP ermöglichen zu einer Lösung zu gelangen wenn die Turingmaschine einen Finalzustand erreicht hat. Darüber hinaus werden noch die Anfangs- und Abschlussregeln gebraucht um das PKP auf den Ausgangszustand der Turingmaschine zu initialisieren und die Lösung des PKPs zu bilden.
			
			Diese Konstruktionsregeln sehen folgendermaßen aus (vgl. \cite{wegener}):
			\begin{definition}
				\label{def-simulation}
				Für eine gegebene Turingmaschine $M = (Q, \Sigma, \varGamma, \delta, q_o, \varepsilon ,Q_f)$ mit der Menge der inneren Zustände $Q$, dem Eingabealphabet $\Sigma$, dem Bandalphabet $\varGamma$, dem (inneren) Startzustand $q_0$, dem leeren Symbol $\varepsilon$, sowie der Menge an (inneren) Finalzuständen $Q_f$ kann mit nachfolgenden Regeln eine Instanz des PKPs konstruiert werden, so dass dieses genau dann eine Lösung hat, wenn die Turingmaschine für das Eingabewort $w$ in einen Endzustand gelangt.
				\begin{tabbing}
					XXXX \= XXXXXXX \= X \kill
						\textbf{1. Anfangsregel}\\
							\> \textbullet $\begin{bmatrix}\sharp\sharp q_0w\sharp \\ \sharp\end{bmatrix}$ \> (Startwortpaar)\\
						\textbf{2. Kopierregel}\\
							\> \textbullet$\begin{bmatrix} a \\ a \end{bmatrix}$ \> für alle $a \in \varGamma \cup \left\lbrace \sharp \right\rbrace$\\
						\textbf{3. Überführungsregeln}\\
							\> \textbullet$\begin{bmatrix} cq' \\ qa \end{bmatrix}$ \> falls $(qa \rightarrow q'cR) \in \delta$, für $q \in Q, a \in \varGamma$ \\
							\> \textbullet$\begin{bmatrix} q'bc \\ bqa \end{bmatrix}$ \> falls $(qa \rightarrow q'cL) \in \delta$, für $q \in Q, a \in \varGamma$\\
						\textbf{4. Aufholregeln}\\
							\> \textbullet$\begin{bmatrix} q \\ aq \end{bmatrix}$ \> für alle $a \in \varGamma$ und $q \in Q_f$\\
							\> \textbullet$\begin{bmatrix} q \\ qa \end{bmatrix}$ \> für alle $a \in \varGamma$ und $q \in Q_f$\\
						\textbf{5. Abschlussregel}\\
							\> \textbullet$\begin{bmatrix} \sharp \\ q\sharp\sharp\end{bmatrix}$ \> für alle $q \in Q_f$

				\end{tabbing} 
			\end{definition}
			Anmerkung: Die hiermit simulierte Turingmaschine bewegt ihren Lese- und Schreibkopf in jedem Rechenschritt entweder nach Rechts oder nach Links. Zusätzliche Regeln, die benötigt werden wenn der Lese- und Schreibkopf den Rand des beschriebenen Teils des Bands erreicht, wurden der Übersichtlichkeit wegen weggelassen. Diese können in \cite{wegener} nachgelesen werden.
			
			Die Simulation des Rechenwegs der Turingmaschine kann man sich folgendermaßen visualisieren: Man hat zwei übereinander stehende Wortfolgen, bei der das untere Wort jeweils die bereits abgeschlossenen Rechenschritte darstellt, und das obere entsprechend zusätzlich den darauf folgenden Rechenschritt abbildet. So eilt das untere Wort dem oberen Wort so lange hinterher, bis die Aufholregeln eingesetzt werden können, sprich die Turingmaschine einen Finalzustand erreicht hat. Diese Aufholregeln ermöglichen es nun dem unteren Wort Schritt für Schritt aufzuholen, bis nur noch das - aus der Abschlussregel konstruierte - Wortpaar verwendet werden kann, und es das obere Wort einholt. Damit hat diese PKP Instanz genau dann eine Lösung wenn die Turingmaschine einen Finalzustand erreicht. Die Konstruktionsregeln aus Definition \ref{def-simulation} lassen nur unter dieser Bedingung ein Aufholen des unteren Wortes zu.
			
			Das folgende Beispiel dient der Verdeutlichung des Simulationsablaufs:
			\begin{bsp}
				Gegeben sei eine Turingmaschine $M$, die sich derzeit im Zustand $Q_t = 0110101q_2100010$ befindet. Durch die Anwendung der Regel $q_21 \rightarrow q_11R$ gelangt sie in den Folgezustand $Q_{t+1} = 01101011q_100010$. Der darauf folgende Rechenschritt soll nun mit Hilfe des nach Definition \ref{def-simulation} konstruierten PKPs simuliert werden. Dabei findet folgende Regel Anwendung: $q_10\rightarrow q_11R$
				\begin{tabbing}
				XXXX \= XX \= X\kill
				\>\textbullet Ausgangslage\\
				\>\> $...0110101q_2100010\sharp01101011q_100010\sharp$\\
				\>\> $...0110101q_2100010\sharp$\\
				\>\textbullet Anwendung der Kopierregel\\
				\>\> $...0110101q_2100010\sharp01101011q_100010\sharp0$\\
				\>\>$ ...0110101q_2100010\sharp0$\\
				\>\textbullet Anwendung der Kopierregel\\
				\>\> $...0110101q_2100010\sharp01101011q_100010\sharp01$\\
				\>\>$ ...0110101q_2100010\sharp01$\\
				\>\textbullet Mehrfache Anwendung der Kopierregeln\\
				\>\> $...0110101q_2100010\sharp01101011q_100010\sharp01101011$\\
				\>\>$ ...0110101q_2100010\sharp01101011$\\
				\>\textbullet Überführungsregel zu $q_10\rightarrow q_11R$\\
				\>\> $...0110101q_2100010\sharp01101011q_100010\sharp011010111q_1$\\
				\>\>$ ...0110101q_2100010\sharp01101011q_10$\\
				\>\textbullet Erneute Mehrfache Anwendung der Kopierregeln\\
				\>\> $...0110101q_2100010\sharp01101011q_100010\sharp011010111q_10010\sharp$\\
				\>\>$ ...0110101q_2100010\sharp01101011q_100010\sharp$\\
				\end{tabbing}
				Somit erhalten wir den nachfolgenden Turingrechenschritt durch obenstehende Simulation mit $Q_{t+2} = 011010111q_10010$.
			\end{bsp}

	\subsection{Reduktion des Halteproblems}
	
		Wie bereits im vorangegangen Abschnitt beschrieben, hat die nach Definition \ref{def-simulation} konstruierte Instanz des Postschen Korrespondenzproblems nur dann eine Lösung, wenn die Turingmaschine $M$ mit der Eingabe $w$ einen Finalzustand erreicht, sprich terminiert. Das Halteproblem für Turingmaschinen besagt allerdings, dass es nicht entscheidbar ist, ob eine Turingmaschine für eine beliebige Eingabe terminiert. Damit ist das PKP ebenfalls nicht entscheidbar.
		
		\begin{satz}
		Sei $M$ eine Turingmaschine und $w$ ihre Eingabe, so lässt sich das Halteproblem für Turingmaschinen durch die Übergangsfunktion $f$ (nach Definition \ref{def-simulation}) auf das PKP reduzieren:
		\[\chi_{Halte} (M, w) \Leftrightarrow \chi_{PKP}(f(M, w))\]
		Damit ist bewiesen, dass das PKP ebenfalls nicht berechenbar ist.
		\end{satz}

\section{Beweise mit Hilfe des PKPs}

	In diesem Kapitel soll mit Hilfe des PKPs die Nichtberechenbarkeit zweier weiterer Probleme aus dem Gebiet der formalen Sprachen bewiesen werden. Konkret geht es um den Mehrdeutigkeitstest für eine kontextfreie Grammatik (kfG) und die Frage nach der Äquivalenz zweier kontextfreier Sprachen.
	
	\subsection{Mehrdeutigkeitstest}
	\label{subsec-mehrdeutigkeit}
		
		Der Mehrdeutigkeitstest sei wie folgt definiert:
		\begin{definition}
			Eine kontextfreie Grammatik ist genau dann Mehrdeutig, wenn sich mindestens ein Wort auf mindestens zwei verschiedene Weise aus dieser ableiten lassen. Somit sei die charakteristische Funktion $\chi_{Mehrdeutig}(G)$ definiert als
			  \[
			     \chi_{Mehrdeutig}(G)=\left\{\begin{array}{ll} 1, & \text{G ist mehrdeutig} \\
			         0, &\text{G ist eindeutig}\end{array}\right. .
			  \]
		\end{definition}
		
		Um das spezielle PKP auf den Mehrdeutigkeitstest zu reduzieren konstruieren wir zu einer gegebenen Instanz des speziellen PKPs mit $K = \left\lbrace (x_1, y_1), ..., (x_k, y_k) \right\rbrace$ über dem endlichen Alphabet $\Sigma$ und den zusätzlichen Symbolen $I = \{a_1, ..., a_k\} \notin \Sigma$ zunächst zwei kontextfreie Grammatiken die offensichtlich eindeutig sind:
		\newline\newline
		$G_x = (\{S_x\}, T, P_x, S_x)$ mit $T = \Sigma \cup I$ und $P_x = \{S_x \rightarrow x_1 S_x a_1 | ... | x_n S_x a_n | x_1 a_1\}$.\\ \\
		Analog dazu konstruieren wir eine zweite Grammatik $G_y$. Sowie eine dritte Grammatik $G$ mit \newline\newline
		$G = (\{S, S_x, S_y\}, T, P, S)$, mit $P = (S \rightarrow S_x | S_y) \cup P_x \cup P_y$.\\
		
		Es lassen sich folgende Beobachtungen machen:
		\begin{itemize}
		\item Wie bereits festgestellt sind $G_x$ und $G_y$ offensichtlich eindeutig.
		\item Die Grammatiken $G_x$ und $G_y$ erzeugen alle Wörter der Form $x_{i_k}...x_{i_1}a_{i_1}...a_{i_k}$ und $y_{i_k}...y_{i_1}a_{i_1}...a_{i_k}$. Wobei gilt $x_{i_1} = x_1$ und $a_{i_1} = a_1$ und analog für $y_{i_1}$.
		\item $G$ ist genau dann mehrdeutig, wenn $G_x$ und $G_y$ mindestens ein gemeinsames Wort erzeugen.
		\item Wenn $G$ mehrdeutig ist, dann hat das PKP folglich mindestens eine Lösung $x_{i_k}...x_{i_1} = y_{i_k}...y_{i_1}$ mit der Indexfolge $I = {i_1, i_2, ... i_k}$.
		\end{itemize}
		
		\begin{satz}
		Aus den oben gemachten Beobachtungen folgt, dass der Mehrdeutigkeitstest für eine kontextfreie Grammatik $G$ nicht berechenbar ist. Die Reduktionsfunktion ist die oben dargestellte Konstruktion der drei Grammatiken zu einer gegebenen Instanz $K$ des PKPs. Somit gilt:
		\[\chi_{PKP} (K) \Leftrightarrow \chi_{Mehrdeutig}(f(K))\]
		Mit der oben beschriebenen Übergangsfunktion $f: K \mapsto G$.
		\end{satz}
		

	\subsection{Äquivalenzproblem}
	
		Die Definition des Äquivalenzproblems lautet wie folgt:
		
		\begin{definition}
			Seien $G_1$ und $G_2$ zwei kontextfreie Grammatiken und $L(G_1)$ sowie $L(G_2)$ die von ihnen erzeugten Sprachen. Dann ist
			\[
				\chi_{"Aquivalenz}(G_1, G_2)=\left\{\begin{array}{ll} 1, & L(G_1) = L(G_2) \\
							         0, &\text{sonst}\end{array}\right. .
			\]
		\end{definition}
		
		Um zu beweisen, dass das Äquivalenzproblem ebenfalls nicht berechenbar ist, verwenden wir die Grammatiken $G_x$ und $G_y$ aus Abschnitt \ref{subsec-mehrdeutigkeit}. Der Beweis für das Mehrdeutigkeitsproblem hat auch bereits bewiesen, dass das Schnittproblem ($L(G_x) \cap L(G_y) = \emptyset$) nicht berechenbar ist, da hierdurch direkt gezeigt werden könnte, dass die Vereinigung beider Grammatiken eindeutig ist. Ferner lässt sich feststellen, dass beide Grammatiken sogar deterministisch kontextfrei\footnote{Deterministisch kontextfreie Grammatiken bilden eine Teilmenge der kontextfreien Grammatiken und zeichnen sich dadurch aus, dass diese von einem deterministischen Kellerautomaten akzeptiert werden können.} sind. Daher können wir uns die Eigenschaft zu nutze machen, dass det. kfGs unter der Komplementbildung abgeschlossen sind\footnote{Hierzu müssen beim akzeptierenden Kellerautomaten nur die Finalzustandsmengen komplementiert werden.}. Des Weiteren sind kfGs - wie bereits in Abschnitt \ref{subsec-mehrdeutigkeit} gezeigt - unter der Vereinigung abgeschlossen.

		\begin{satz}
		\label{satz-aequivalenz}
			Durch die folgenden Äquivalenzumformungen lässt sich das Schnittproblem det. kfG auf das Äquivalenzproblem kfG reduzieren. Dabei seien $G_1$ und $G_2$ det. kfG:
			
			\begin{tabbing}
				(G1,G2) in Schnittproblem \= Rechts \kill
				$(G_1, G_2) \in$ Schnittproblem \>$\Leftrightarrow L(G_1) \cap L(G_2) = \emptyset$ \\
												\>$\Leftrightarrow L(G_1) \subseteq \overline{L(G_2)}$ \\
												\>$\Leftrightarrow L(G_1) \subseteq L(G'_2)$ \\
												\>$\Leftrightarrow L(G_1) \cup L(G'_2) = L(G'_2)$ \\
												\>$\Leftrightarrow L(G_3) = L(G'_2)$ \\
												\>$\Leftrightarrow (G_3, G'_2) \in$ Äquivalenzproblem 
			\end{tabbing}
				Mit dem Übergang zur Komplementgrammatik $G_2 \mapsto G'_2$ (für dkfG) und\\				
				dem Übergang zur Vereinigungsgrammatik $G_1, G'_2 \mapsto G_3$ (für kfG).
			Folglich gilt (unter Zuhilfenahme der jeweiligen vorgestellten Übergangsfunktionen):
			\[
				\chi_{PKP}(K) \Leftrightarrow \chi_{Mehrdeutig}(G) \Leftrightarrow \chi_{Schnitt}(G_x, G_y) \Leftrightarrow \chi_{"Aquivalenz}(G_3, G'_2)
			\]
			Womit bewiesen ist, dass das Äquivalenzproblem kontextfreier Grammatiken ebenfalls nicht berechenbar ist \cite{schoening}.
		\end{satz}

		An dieser Stelle sei noch angemerkt, dass sämtliche Zwischenergebnisse (oder Probleme) der Umformung in Satz \ref{satz-aequivalenz} selbstverständlich ebenfalls nicht berechenbar sind. Wichtig ist auch, dass dieser Beweis ausschließlich für die jeweiligen Mengen von Grammatiken gilt. Beispielsweise ist noch nicht bewiesen, ob es sich beim Äquivalenzproblem zweier det. kfG ebenfalls um ein nichtberechenbares Problem handelt (\cite{schoening}).

\section{Fazit}

	Diese Ausarbeitung hat gezeigt, wie man mit Hilfe des PKPs für viele weitere Probleme der theoretischen Informatik beweisen kann, dass diese nicht berechenbar sind. Und das trotz dessen, dass das PKP auf den ersten Blick wie eine harmlose Knobelaufgabe aussieht. Oder ein wenig abstrakter formuliert, wie man mit Hilfe eines Hilfskonstrukts eine Eigenschaft eines Problems für ein weiteres Problem nachweist, in dem nachgewiesen wird, dass das Hilfskonstrukt ebenfalls über diese Eigenschaft verfügt. Anschließend muss dieses auf das gewünschte Problem reduziert werden.

\def\refname{Literaturverzeichnis}
\printbibliography    

\end{document}
